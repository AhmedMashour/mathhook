name: Cross-Platform Benchmarks

on:
  pull_request:
    paths: ['crates/**/*.rs', 'crates/mathhook-benchmarks/**', 'Cargo.toml']
  push:
    branches: [main, master]
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

env:
  CARGO_TERM_COLOR: always

# Rust benchmarks
jobs:
  rust:
    name: Rust
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2

      - name: Run benchmarks
        run: |
          mkdir -p benchmark-results
          if [ -f "crates/mathhook-benchmarks/Cargo.toml" ]; then
            cargo bench -p mathhook-benchmarks --benches 2>&1 | tee benchmark-output.txt
            echo '{"platform":"rust","status":"success","note":"Criterion HTML reports available"}' > benchmark-results/rust.json
          else
            echo '{"platform":"rust","status":"not_found","benchmarks":{}}' > benchmark-results/rust.json
          fi

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: rust-benchmark-results
          path: benchmark-results/rust.json

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: criterion-reports
          path: target/criterion/

  # Python benchmarks
  python:
    name: Python
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2

      - name: Build and run
        run: |
          mkdir -p benchmark-results
          if [ -f "crates/mathhook-python/Cargo.toml" ]; then
            pip install maturin
            cd crates/mathhook-python && maturin develop --release && cd ../..
            if [ -f "crates/mathhook-benchmarks/public/python/bench_mathhook.py" ]; then
              cd crates/mathhook-benchmarks/public/python
              # stderr has "Running..." messages, stdout has JSON
              python3 bench_mathhook.py --json --iterations 50 2>/dev/null > ../../../../benchmark-results/python.json || \
                echo '{"platform":"python","status":"run_error","benchmarks":{}}' > ../../../../benchmark-results/python.json
              # Validate JSON
              if ! python3 -c "import json; json.load(open('../../../../benchmark-results/python.json'))" 2>/dev/null; then
                echo '{"platform":"python","status":"json_error","benchmarks":{}}' > ../../../../benchmark-results/python.json
              fi
            else
              echo '{"platform":"python","status":"script_not_found","benchmarks":{}}' > benchmark-results/python.json
            fi
          else
            echo '{"platform":"python","status":"not_found","benchmarks":{}}' > benchmark-results/python.json
          fi

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: python-benchmark-results
          path: benchmark-results/python.json

  # Node.js benchmarks
  node:
    name: Node.js
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20' }
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2

      - name: Build and run
        run: |
          mkdir -p benchmark-results
          if [ -f "crates/mathhook-node/package.json" ]; then
            cd crates/mathhook-node && npm install && npm run build && cd ../..
            if [ -f "crates/mathhook-benchmarks/public/node/bench_mathhook.js" ]; then
              cd crates/mathhook-benchmarks/public/node
              # stderr has status messages, stdout has JSON
              node bench_mathhook.js --json --iterations 50 2>/dev/null > ../../../../benchmark-results/node.json || \
                echo '{"platform":"node","status":"run_error","benchmarks":{}}' > ../../../../benchmark-results/node.json
              # Validate JSON
              if ! python3 -c "import json; json.load(open('../../../../benchmark-results/node.json'))" 2>/dev/null; then
                echo '{"platform":"node","status":"json_error","benchmarks":{}}' > ../../../../benchmark-results/node.json
              fi
            else
              echo '{"platform":"node","status":"script_not_found","benchmarks":{}}' > benchmark-results/node.json
            fi
          else
            echo '{"platform":"node","status":"not_found","benchmarks":{}}' > benchmark-results/node.json
          fi

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: node-benchmark-results
          path: benchmark-results/node.json

  # Deploy dashboard to GitHub Pages
  deploy:
    name: Deploy Dashboard
    needs: [rust, python, node]
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with: { path: artifacts }
        continue-on-error: true
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }

      - name: Prepare Criterion reports
        run: |
          # Move Criterion reports to expected location if present
          if [ -d "artifacts/criterion-reports" ]; then
            mkdir -p criterion-reports
            cp -r artifacts/criterion-reports/* criterion-reports/
            echo "Criterion reports available:"
            ls -la criterion-reports/
          else
            echo "No Criterion reports found in artifacts"
          fi

      - name: Generate dashboard
        run: python3 scripts/ci/generate_dashboard.py artifacts gh-pages criterion-reports

      - uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./gh-pages
          publish_branch: gh-pages
          force_orphan: true
          commit_message: "Update benchmark results [skip ci]"

  # Update baselines on push
  baselines:
    name: Update Baselines
    needs: [rust, python, node]
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - uses: actions/checkout@v4
        with: { token: '${{ secrets.GITHUB_TOKEN }}' }
      - uses: actions/download-artifact@v4
        with: { path: artifacts }
        continue-on-error: true

      - name: Update baselines
        run: bash scripts/ci/update_baselines.sh artifacts

      - name: Commit
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add benchmarks/*_baseline.json 2>/dev/null || true
          git diff --quiet --cached || git commit -m "Update baselines [skip ci]"
          git push || true
        continue-on-error: true

  # PR comment with results
  pr-comment:
    name: PR Comment
    needs: [rust, python, node]
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/github-script@v7
        with:
          script: |
            const body = `## Benchmark Results

            | Platform | Status |
            |----------|--------|
            | Rust | ${{ needs.rust.result == 'success' && ':white_check_mark:' || ':warning:' }} |
            | Python | ${{ needs.python.result == 'success' && ':white_check_mark:' || ':grey_question:' }} |
            | Node.js | ${{ needs.node.result == 'success' && ':white_check_mark:' || ':grey_question:' }} |

            [View Dashboard](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/)`;

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existing = comments.find(c => c.user.type === 'Bot' && c.body.includes('Benchmark Results'));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body
              });
            }
